# API Flask de Web Scraping - Dados Vitivin√≠colas

Esta √© uma API Flask que realiza web scraping do site da Embrapa para extrair dados vitivin√≠colas brasileiros.

## Funcionalidades

- **Autentica√ß√£o HTTP Basic**: Acesso seguro aos endpoints
- **5 Endpoints de dados**: Produ√ß√£o, Processamento, Comercializa√ß√£o, Importa√ß√£o e Exporta√ß√£o
- **Filtros por ano e sub-op√ß√µes**: Par√¢metros opcionais para refinar consultas
- **Parsing inteligente de tabelas**: Extra√ß√£o estruturada de dados HTML
- **Documenta√ß√£o Swagger**: Interface interativa para testar a API
- **Tratamento de erros**: Logging detalhado e respostas estruturadas
- **Sistema de cache tr√™s camadas**: Cache Redis (curto/longo prazo) + fallback CSV local
- **Alta disponibilidade**: Garante resposta mesmo quando web scraping e Redis falham

## Configura√ß√£o do Ambiente

### Op√ß√£o 1: Docker (Recomendado)

#### Deploy R√°pido com Versionamento Autom√°tico
```bash
# Deploy completo com rebuild e versionamento
python docker-deploy.py

# Deploy para produ√ß√£o
python docker-deploy.py --env production

# Deploy sem rebuild (usar imagem existente)
python docker-deploy.py --no-rebuild

# Deploy com logs
python docker-deploy.py --logs
```

#### Comandos Docker Manuais
```bash
# Construir imagem com versionamento
python docker-build.py

# Construir para produ√ß√£o
python docker-build.py --env production

# Iniciar com docker-compose
docker-compose up -d

# Ver logs
docker-compose logs -f app

# Parar containers
docker-compose down

# Rebuild completo
docker-compose down && docker-compose build --no-cache && docker-compose up -d
```

#### Verificar Vers√£o no Docker
```bash
# Testar API e ver vers√£o atual
curl http://localhost:5000/heartbeat

# Ver informa√ß√µes da imagem Docker
docker images flask-webscraping-api

# Ver labels da imagem (metadados de vers√£o)
docker inspect flask-webscraping-api:latest
```

### Op√ß√£o 2: Ambiente Local

#### 1. Criar e Ativar Ambiente Virtual

**Windows:**
```bash
# Criar ambiente virtual
python -m venv venv

# Ativar ambiente virtual
venv\Scripts\activate
```

**Linux/Mac:**
```bash
# Criar ambiente virtual
python -m venv venv

# Ativar ambiente virtual
source venv/bin/activate
```

#### 2. Instalar Depend√™ncias

```bash
pip install -r requirements.txt
```

#### 3. Executar a Aplica√ß√£o

```bash
python app.py
```

A aplica√ß√£o estar√° dispon√≠vel em: `http://localhost:5000`

## üöÄ Deploy em Produ√ß√£o (AWS Elastic Beanstalk)

### Gerar Pacote de Deploy

Para fazer deploy no AWS Elastic Beanstalk, primeiro gere o pacote ZIP:

```bash
# Execute no diret√≥rio do projeto
python create_eb_package.py
```

**Sa√≠da esperada:**
```
üìà Incrementando vers√£o...
‚úÖ Nova vers√£o: 1.1.4
üì¶ Criando pacote: flask-webscraping-api-v1.1.4-20250525-220000.zip
üìè Tamanho: 0.01 MB
‚úÖ Pacote criado com sucesso!
```

### Documenta√ß√£o Completa de Deploy

- **üìã Guia passo a passo**: [`AWS_DEPLOY_GUIDE.md`](AWS_DEPLOY_GUIDE.md)
- **‚öôÔ∏è Configura√ß√µes de deploy**: [`DEPLOY_README.md`](DEPLOY_README.md)

### Deploy R√°pido

1. **Gerar pacote**: `python create_eb_package.py`
2. **Acessar AWS**: [Elastic Beanstalk Console](https://console.aws.amazon.com/elasticbeanstalk/)
3. **Criar aplica√ß√£o**: Python 3.11 platform
4. **Upload**: Arquivo ZIP gerado
5. **Configurar**: Vari√°veis de ambiente (ver DEPLOY_README.md)
6. **Testar**: `https://sua-app.elasticbeanstalk.com/heartbeat`

### Atualiza√ß√µes Futuras

```bash
# Gerar nova vers√£o
python create_eb_package.py

# Deploy via console AWS
# Upload do novo arquivo ZIP gerado
```

> üí° **Versionamento autom√°tico**: O script incrementa a vers√£o a cada execu√ß√£o!

---

## Endpoints Dispon√≠veis

### Autentica√ß√£o
- **Usu√°rio 1**: `user1` / `password1`
- **Usu√°rio 2**: `user2` / `password2`

### Endpoints de Dados

| Endpoint | Descri√ß√£o | Par√¢metros Opcionais | Autentica√ß√£o |
|----------|-----------|---------------------|---------------|
| `/producao` | Dados de produ√ß√£o | `year`, `sub_option` | ‚úÖ Requerida |
| `/processamento` | Dados de processamento | `year`, `sub_option` | ‚úÖ Requerida |
| `/comercializacao` | Dados de comercializa√ß√£o | `year`, `sub_option` | ‚úÖ Requerida |
| `/importacao` | Dados de importa√ß√£o | `year`, `sub_option` | ‚úÖ Requerida |
| `/exportacao` | Dados de exporta√ß√£o | `year`, `sub_option` | ‚úÖ Requerida |

### Endpoints de Monitoramento

| Endpoint | Descri√ß√£o | Autentica√ß√£o |
|----------|-----------|--------------|
| `/heartbeat` | Health check da API | ‚ùå N√£o requerida |

### Documenta√ß√£o Swagger
Acesse: `http://localhost:5000/apidocs/`

### Collection Postman
- **Arquivo**: `postman_collection.json`
- **Guia de uso**: `POSTMAN_GUIDE.md`
- **Importar no Postman**: Import > Upload Files > Selecionar `postman_collection.json`

## Par√¢metros de Filtro

### Par√¢metro `year`
- **Tipo**: Integer
- **Range v√°lido**: 1970-2024
- **Descri√ß√£o**: Ano para filtrar os dados (v√°lido para todas as APIs)
- **Exemplo**: `?year=2023`

### Par√¢metro `sub_option`
- **Tipo**: String
- **Descri√ß√£o**: Sub-op√ß√£o espec√≠fica para cada endpoint
- **Valida√ß√£o**: Lista fechada de valores por endpoint

#### Valores v√°lidos por endpoint:

**`/producao`**
- `VINHO DE MESA`
- `VINHO FINO DE MESA (VINIFERA)`
- `SUCO DE UVA`
- `DERIVADOS`

**`/processamento`**
- `viniferas`
- `americanas`
- `mesa`
- `semclass`

**`/comercializacao`**
- `VINHO DE MESA`
- `ESPUMANTES`
- `UVAS FRESCAS`
- `SUCO DE UVA`

**`/importacao`**
- `vinhos`
- `espumantes`
- `frescas`
- `passas`
- `suco`

**`/exportacao`**
- `vinho`
- `uva`
- `espumantes`
- `suco`

### Valida√ß√£o de Par√¢metros
- Par√¢metros inv√°lidos retornam erro **HTTP 400** com mensagem explicativa
- Ambos os par√¢metros s√£o **opcionais**
- Podem ser usados individualmente ou em combina√ß√£o

## Exemplos de Uso

### 1. Usando curl

```bash
# Dados de produ√ß√£o (sem filtros)
curl -u user1:password1 "http://localhost:5000/producao"

# Dados de produ√ß√£o filtrados por ano
curl -u user1:password1 "http://localhost:5000/producao?year=2023"

# Dados de produ√ß√£o com sub-op√ß√£o espec√≠fica
curl -u user1:password1 "http://localhost:5000/producao?sub_option=VINHO%20DE%20MESA"

# Dados de produ√ß√£o com ambos os filtros
curl -u user1:password1 "http://localhost:5000/producao?year=2023&sub_option=SUCO%20DE%20UVA"

# Dados de processamento com filtros
curl -u user1:password1 "http://localhost:5000/processamento?year=2022&sub_option=viniferas"

# Dados de exporta√ß√£o com filtros
curl -u user1:password1 "http://localhost:5000/exportacao?year=2023&sub_option=vinho"

# Exemplo de erro - ano inv√°lido (retorna HTTP 400)
curl -u user1:password1 "http://localhost:5000/producao?year=1969"

# Exemplo de erro - sub-op√ß√£o inv√°lida (retorna HTTP 400)
curl -u user1:password1 "http://localhost:5000/producao?sub_option=OPCAO_INEXISTENTE"

# Health check da API (sem autentica√ß√£o)
curl "http://localhost:5000/heartbeat"
```

### 2. Usando Python requests

```python
import requests
from requests.auth import HTTPBasicAuth

# Configurar autentica√ß√£o
auth = HTTPBasicAuth('user1', 'password1')

# Exemplo 1: Requisi√ß√£o b√°sica sem filtros
response = requests.get(
    'http://localhost:5000/producao',
    auth=auth
)

if response.status_code == 200:
    data = response.json()
    print("Dados de produ√ß√£o:", data)
else:
    print(f"Erro: {response.status_code}")

# Exemplo 2: Requisi√ß√£o com filtros v√°lidos
response = requests.get(
    'http://localhost:5000/producao',
    auth=auth,
    params={
        'year': '2023',
        'sub_option': 'VINHO DE MESA'
    }
)

if response.status_code == 200:
    data = response.json()
    print("Dados filtrados:", data)
else:
    print(f"Erro: {response.status_code}")

# Exemplo 3: Tratamento de erro de valida√ß√£o
response = requests.get(
    'http://localhost:5000/producao',
    auth=auth,
    params={'year': '1969'}  # Ano inv√°lido
)

if response.status_code == 400:
    error_data = response.json()
    print(f"Erro de valida√ß√£o: {error_data['error']}")
elif response.status_code == 200:
    data = response.json()
    print("Dados:", data)

# Exemplo 4: Diferentes endpoints com suas sub-op√ß√µes
endpoints_examples = {
    'processamento': {'year': '2023', 'sub_option': 'viniferas'},
    'comercializacao': {'year': '2022', 'sub_option': 'ESPUMANTES'},
    'importacao': {'year': '2023', 'sub_option': 'vinhos'},
    'exportacao': {'year': '2023', 'sub_option': 'uva'}
}

for endpoint, params in endpoints_examples.items():
    response = requests.get(
        f'http://localhost:5000/{endpoint}',
        auth=auth,
        params=params
    )
    
    if response.status_code == 200:
        data = response.json()
        cache_status = data.get('cached', 'unknown')
        print(f"‚úÖ {endpoint}: Dados obtidos com sucesso (cache: {cache_status})")
    else:
        print(f"‚ùå {endpoint}: Erro {response.status_code}")

# Exemplo 5: Monitoramento de cache e performance
import time

def test_cache_performance():
    """Demonstra o funcionamento do cache"""
    
    # Primeira requisi√ß√£o (dados frescos)
    start_time = time.time()
    response1 = requests.get('http://localhost:5000/producao?year=2023', auth=auth)
    time1 = time.time() - start_time
    
    if response1.status_code == 200:
        data1 = response1.json()
        print(f"1¬™ requisi√ß√£o: {time1:.2f}s - Cache: {data1.get('cached', 'unknown')}")
    
    # Segunda requisi√ß√£o (cache hit)
    start_time = time.time()
    response2 = requests.get('http://localhost:5000/producao?year=2023', auth=auth)
    time2 = time.time() - start_time
    
    if response2.status_code == 200:
        data2 = response2.json()
        print(f"2¬™ requisi√ß√£o: {time2:.2f}s - Cache: {data2.get('cached', 'unknown')}")
        print(f"Melhoria de performance: {((time1 - time2) / time1 * 100):.1f}%")

# Executar teste de performance
test_cache_performance()
```

## Estrutura de Resposta

### Resposta Padr√£o com Cache
```json
{
  "data": {
    "header": [
      ["Coluna1", "Coluna2", "Coluna3"]
    ],
    "body": [
      {
        "item_data": ["Item Principal"],
        "sub_items": [
          ["Sub-item 1", "Valor 1"],
          ["Sub-item 2", "Valor 2"]
        ]
      }
    ],
    "footer": [
      ["Total", "Valor Total"]
    ]
  },
  "cached": false
}
```

### Indicadores de Cache
- `"cached": false` - Dados frescos obtidos via web scraping
- `"cached": "short_term"` - Dados do cache de curto prazo (5 min)
- `"cached": "fallback"` - Dados do cache de fallback (30 dias)

## Depend√™ncias Principais

- **Flask**: Framework web
- **requests**: Cliente HTTP para web scraping
- **BeautifulSoup4**: Parser HTML/XML
- **Flask-HTTPAuth**: Autentica√ß√£o HTTP Basic
- **flasgger**: Documenta√ß√£o Swagger autom√°tica
- **Redis**: Sistema de cache em mem√≥ria

## üóÑÔ∏è Sistema de Cache Tr√™s Camadas

A API implementa um **sistema de cache robusto de tr√™s camadas** que garante alta disponibilidade e performance mesmo em cen√°rios de falha:

### Camadas do Sistema

#### üöÄ **Camada 1: Cache Curto Prazo (Redis)**
- **TTL**: 5 minutos (configur√°vel via `SHORT_CACHE_TTL`)
- **Prop√≥sito**: Respostas r√°pidas para requisi√ß√µes frequentes
- **Comportamento**: Dados frescos para uso imediato

#### üõ°Ô∏è **Camada 2: Cache Fallback (Redis)**  
- **TTL**: 30 dias (configur√°vel via `FALLBACK_CACHE_TTL`)
- **Prop√≥sito**: Backup quando web scraping falha
- **Comportamento**: Dados hist√≥ricos para alta disponibilidade

#### üìÅ **Camada 3: Fallback CSV (Arquivos Locais)**
- **TTL**: Arquivos est√°ticos locais  
- **Prop√≥sito**: √öltima linha de defesa quando Redis est√° indispon√≠vel
- **Comportamento**: Dados estruturados em CSV convertidos para formato API

### Fluxo de Execu√ß√£o

```mermaid
graph TD
    A[Requisi√ß√£o API] --> B{Cache Curto<br/>5min}
    B -->|HIT| C[Retorna Dados Cache]
    B -->|MISS| D[Web Scraping]
    D -->|Sucesso| E[Salva em Ambos Caches]
    E --> F[Retorna Dados Frescos]
    D -->|Falha| G{Cache Fallback<br/>30 dias}
    G -->|HIT| H[Retorna Dados Cache Antigo]
    G -->|MISS| I{CSV Fallback<br/>Arquivos Locais}
    I -->|Encontrado| J[Converte CSV‚ÜíAPI]
    J --> K[Retorna Dados CSV]
    I -->|N√£o Encontrado| L[Erro 503 - Indispon√≠vel]
```

### Mapeamento Endpoint-to-CSV

O sistema mapeia automaticamente cada endpoint para arquivos CSV espec√≠ficos:

```python
ENDPOINT_CSV_MAP = {
    'producao': {
        'default': 'Producao.csv',
        'sub_options': {
            'VINHO DE MESA': 'Producao.csv',
            'VINHO FINO DE MESA (VINIFERA)': 'Producao.csv',
            'SUCO DE UVA': 'Producao.csv',
            'DERIVADOS': 'Producao.csv'
        }
    },
    'processamento': {
        'default': 'ProcessaViniferas.csv',
        'sub_options': {
            'viniferas': 'ProcessaViniferas.csv',
            'americanas': 'ProcessaAmericanas.csv',
            'mesa': 'ProcessaMesa.csv',
            'semclass': 'ProcessaSemclass.csv'
        }
    },
    'comercializacao': {
        'default': 'Comercio.csv'
    },
    'importacao': {
        'default': 'ImpVinhos.csv',
        'sub_options': {
            'vinhos': 'ImpVinhos.csv',
            'espumantes': 'ImpEspumantes.csv',
            'frescas': 'ImpFrescas.csv',
            'passas': 'ImpPassas.csv',
            'suco': 'ImpSuco.csv'
        }
    },
    'exportacao': {
        'default': 'ExpVinho.csv',
        'sub_options': {
            'vinho': 'ExpVinho.csv',
            'uva': 'ExpUva.csv',
            'espumantes': 'ExpEspumantes.csv',
            'suco': 'ExpSuco.csv'
        }
    }
}
```

### Configura√ß√£o CSV Fallback

#### Estrutura de Diret√≥rios
```
data/
‚îî‚îÄ‚îÄ fallback/
    ‚îú‚îÄ‚îÄ Producao.csv
    ‚îú‚îÄ‚îÄ ProcessaViniferas.csv
    ‚îú‚îÄ‚îÄ ProcessaAmericanas.csv
    ‚îú‚îÄ‚îÄ ProcessaMesa.csv
    ‚îú‚îÄ‚îÄ ProcessaSemclass.csv
    ‚îú‚îÄ‚îÄ Comercio.csv
    ‚îú‚îÄ‚îÄ ImpVinhos.csv
    ‚îú‚îÄ‚îÄ ImpEspumantes.csv
    ‚îú‚îÄ‚îÄ ImpFrescas.csv
    ‚îú‚îÄ‚îÄ ImpPassas.csv
    ‚îú‚îÄ‚îÄ ImpSuco.csv
    ‚îú‚îÄ‚îÄ ExpVinho.csv
    ‚îú‚îÄ‚îÄ ExpUva.csv
    ‚îú‚îÄ‚îÄ ExpEspumantes.csv
    ‚îî‚îÄ‚îÄ ExpSuco.csv
```

#### Configura√ß√£o Avan√ßada CSV
```bash
# Configura√ß√£o CSV Fallback
CSV_FALLBACK_DIR=data/fallback    # Default: data/fallback
CSV_CACHE_ENABLED=true            # Default: true
CSV_MAX_CACHE_SIZE=50             # Default: 50 files
CSV_CACHE_TTL=1800                # Default: 1800s (30min)
```

#### Formato de Resposta CSV Fallback
```json
{
  "data": {
    "header": [["Produto", "Quantidade (L.)", "Ano"]],
    "body": [
      {"item_data": ["VINHO DE MESA", "123456789", "2023"], "sub_items": []},
      {"item_data": ["VINHO FINO", "987654321", "2023"], "sub_items": []}
    ],
    "footer": [["TOTAL GERAL", "1567890233", "2023"]]
  },
  "cached": "csv_fallback",
  "data_source": "Local CSV files (Redis unavailable)",
  "freshness": "Static data from local files",
  "endpoint": "producao",
  "status": "success"
}
```

### Estados de Cache na Resposta

A API retorna um campo `cached` que indica a fonte dos dados:

| Valor | Descri√ß√£o | TTL | Performance |
|-------|-----------|-----|-------------|
| `false` | Dados frescos via web scraping | N/A | ‚ö° Tempo real |
| `"short_term"` | Cache curto prazo (Redis) | 5min | ‚ö° Muito r√°pida |
| `"fallback"` | Cache fallback (Redis) | 30d | ‚ö° R√°pida |
| `"csv_fallback"` | Fallback CSV (arquivos locais) | Est√°tico | ‚ö° R√°pida |

### Monitoramento e Estat√≠sticas

#### Endpoint de Estat√≠sticas de Cache
```bash
# Via API (requer autentica√ß√£o)
GET /cache-stats

# Resposta detalhada
{
  "timestamp": "2025-01-26T10:30:00.123456+00:00",
  "redis_available": true,
  "cache_layers": {
    "short_term": {
      "entries": 15,
      "ttl_seconds": 300,
      "status": "active"
    },
    "fallback": {
      "entries": 127,
      "ttl_seconds": 2592000,
      "status": "active"
    },
    "csv_fallback": {
      "status": "active",
      "cache_enabled": true,
      "entries": 12,
      "max_size": 50,
      "hit_rate_percent": 85.5,
      "cache_efficiency": "excellent"
    }
  },
  "csv_fallback_validation": {
    "overall_status": "healthy",
    "total_endpoints": 5,
    "valid_endpoints": 5,
    "existing_files": 15,
    "missing_files": 0
  },
  "overall_status": {
    "active_layers": 3,
    "total_layers": 3,
    "health": "excellent"
  }
}
```

#### Logs Avan√ßados do Sistema
```python
# Logs com emojis para identifica√ß√£o visual
üéØ Cache HIT   - "Layer 1 HIT: Returning short-term cache data"
‚ùå Cache MISS  - "Layer 1 MISS: No short-term cache available"
üåê Web Scraping - "Fresh data fetched and cached"
‚ö†Ô∏è Fallback   - "Layer 2 HIT: Using fallback cache due to scraping failure"
üóÇÔ∏è CSV Fallback - "Layer 3 HIT: Returning CSV fallback data"
üí• All Failed  - "ALL LAYERS FAILED: All data sources unavailable"
```

### Casos de Uso por Cen√°rio

#### ‚úÖ **Cen√°rio Normal**
1. **Requisi√ß√£o** ‚Üí Cache curto (miss) ‚Üí Web scraping ‚Üí Dados frescos
2. **Requisi√ß√£o seguinte** ‚Üí Cache curto (hit) ‚Üí Resposta instant√¢nea

#### ‚ö†Ô∏è **Site Embrapa Indispon√≠vel**
1. **Requisi√ß√£o** ‚Üí Cache curto (miss) ‚Üí Web scraping (falha) ‚Üí Cache fallback (hit) ‚Üí Dados antigos

#### üö® **Redis Indispon√≠vel**  
1. **Requisi√ß√£o** ‚Üí Redis (falha) ‚Üí Web scraping (falha) ‚Üí CSV fallback (hit) ‚Üí Dados est√°ticos

#### üí• **Falha Total**
1. **Requisi√ß√£o** ‚Üí Todas as camadas (falha) ‚Üí Erro 503 com contexto detalhado

### Gerenciamento do Cache

#### Limpeza Manual (se necess√°rio)
```bash
# Conectar ao Redis via Docker
docker exec -it fiap_5mlet_tcm1_grp5-redis-1 redis-cli

# Listar chaves de cache
KEYS short:*
KEYS fallback:*

# Limpar cache espec√≠fico
DEL short:producao:*
DEL fallback:*

# Limpar todo o cache
FLUSHDB
```

#### Valida√ß√£o CSV Fallback
```bash
# Via Python REPL (com aplica√ß√£o rodando)
from cache import CacheManager
cache_manager = CacheManager()

# Validar mapeamento de endpoints
validation = cache_manager.validate_csv_fallback()
print(validation)

# Testar endpoint espec√≠fico
csv_data = cache_manager.get_csv_fallback('producao', {'sub_option': 'VINHO DE MESA'})
print(csv_data)
```

#### Configura√ß√£o de TTL Personalizada
```bash
# Cache mais agressivo (1 minuto)
SHORT_CACHE_TTL=60

# Cache de fallback mais longo (7 dias)
FALLBACK_CACHE_TTL=604800

# Cache CSV com TTL menor (10 minutos)
CSV_CACHE_TTL=600
```

### Vantagens do Sistema Tr√™s Camadas

#### üöÄ **Performance**
- **Respostas sub-segundo**: Cache curto para dados recentes
- **Redu√ß√£o de lat√™ncia**: Evita web scraping desnecess√°rio  
- **Otimiza√ß√£o de recursos**: Menor uso de CPU e rede

#### üõ°Ô∏è **Alta Disponibilidade**
- **Toler√¢ncia a falhas m√∫ltiplas**: 3 camadas independentes
- **Zero downtime**: Sempre h√° uma fonte de dados dispon√≠vel
- **Graceful degradation**: Degrada graciosamente mantendo funcionalidade

#### üìä **Observabilidade**
- **Logs detalhados**: Registra toda a cadeia de fallback
- **M√©tricas em tempo real**: Performance por camada
- **Health checks**: Status completo do sistema de cache

#### üíæ **Flexibilidade**
- **Configura√ß√£o por ambiente**: TTLs ajust√°veis por cen√°rio
- **Dados hist√≥ricos**: Cache fallback mant√©m dados por semanas
- **Dados locais**: CSV garante funcionamento offline

### Detalhes de Implementa√ß√£o T√©cnica

#### Arquitetura do M√≥dulo Cache
```
cache/
‚îú‚îÄ‚îÄ __init__.py          # Exposi√ß√£o das classes principais
‚îú‚îÄ‚îÄ cache_manager.py     # Gerenciador principal (3 camadas)
‚îú‚îÄ‚îÄ redis_client.py      # Cliente Redis com singleton
‚îî‚îÄ‚îÄ csv_fallback.py      # Gerenciador CSV fallback
```

#### Classe CacheManager (Atualizada)
```python
# M√©todos de cache Redis
get_short_cache(endpoint, params)        # Camada 1: Cache 5min
set_short_cache(endpoint, data, params)  # Armazena cache 5min
get_fallback_cache(endpoint, params)     # Camada 2: Cache 30d  
set_fallback_cache(endpoint, data, params) # Armazena cache 30d

# M√©todos de CSV fallback
get_csv_fallback(endpoint, params)       # Camada 3: CSV local
validate_csv_fallback()                  # Valida arquivos CSV
get_csv_fallback_stats()                 # Estat√≠sticas CSV

# Utilit√°rios
clear_cache(endpoint, cache_type)        # Limpa cache espec√≠fico
get_cache_stats()                        # Estat√≠sticas completas (3 camadas)
```

#### Integra√ß√£o com Endpoints (Atualizada)
```python
def get_content_with_cache(endpoint_name, url, cache_manager, logger, params=None):
    # Camada 1: Cache curto prazo (5min)
    cached_response = cache_manager.get_short_cache(endpoint_name, params)
    if cached_response:
        logger.info(f"‚úÖ Layer 1 HIT: short-term cache for {endpoint_name}")
        return cached_response['data'], cached_response['cached']
    
    # Camada 2: Web scraping + armazenamento
    try:
        response = requests.get(url, timeout=30)
        parsed_data = parse_html_content(response.text, logger)
        
        # Armazena em ambos os caches Redis
        cache_manager.set_short_cache(endpoint_name, parsed_data, params)
        cache_manager.set_fallback_cache(endpoint_name, parsed_data, params)
        
        logger.info(f"‚úÖ Fresh data fetched and cached for {endpoint_name}")
        return parsed_data, False
        
    except requests.RequestException as e:
        logger.error(f"‚ùå Web scraping failed for {endpoint_name}: {e}")
        
        # Camada 2: Cache fallback Redis (30d)
        cached_response = cache_manager.get_fallback_cache(endpoint_name, params)
        if cached_response:
            logger.warning(f"‚ö†Ô∏è Layer 2 HIT: fallback cache for {endpoint_name}")
            return cached_response['data'], cached_response['cached']
        
        # Camada 3: CSV fallback (arquivos locais)
        logger.info(f"üóÇÔ∏è Attempting CSV fallback for {endpoint_name}")
        csv_response = cache_manager.get_csv_fallback(endpoint_name, params)
        if csv_response:
            logger.warning(f"‚úÖ Layer 3 HIT: CSV fallback for {endpoint_name}")
            return csv_response, csv_response['cached']
        
        # Todas as camadas falharam
        logger.critical(f"üí• ALL LAYERS FAILED for {endpoint_name}")
        return None, False
```

#### Vari√°veis de Ambiente Completas
```bash
# Configura√ß√£o Redis
REDIS_HOST=localhost              # Default: localhost
REDIS_PORT=6379                  # Default: 6379
REDIS_DB=0                       # Default: 0
REDIS_PASSWORD=                  # Default: None

# Configura√ß√£o Cache TTL
SHORT_CACHE_TTL=300              # Default: 300 (5 min)
FALLBACK_CACHE_TTL=2592000        # Default: 2592000 (30 dias)

# Configura√ß√£o CSV Fallback
CSV_FALLBACK_DIR=data/fallback    # Default: data/fallback
CSV_CACHE_ENABLED=true            # Default: true
CSV_MAX_CACHE_SIZE=50             # Default: 50
CSV_CACHE_TTL=1800                # Default: 1800 (30 min)

# Configura√ß√£o Aplica√ß√£o
LOG_LEVEL=INFO                    # Default: INFO
```

## Versionamento Autom√°tico

A aplica√ß√£o possui um **sistema de versionamento simples** baseado em arquivo que incrementa a vers√£o automaticamente a cada altera√ß√£o.

### Como Funciona
- **Arquivo de vers√£o**: `version.txt` cont√©m a vers√£o atual (formato: MAJOR.MINOR.PATCH)
- **Incremento autom√°tico**: A vers√£o √© incrementada automaticamente nos builds
- **Tipos de incremento**: major (X.0.0), minor (X.Y.0), patch (X.Y.Z) - padr√£o
- **Integra√ß√£o Docker**: Funciona tanto em ambiente local quanto em containers
- **Fallback robusto**: Sistema funciona independente de Git ou outras depend√™ncias

### Scripts de Build e Deploy

#### Build Local
```bash
# Build local com incremento patch (padr√£o)
python build.py --type local

# Build com incremento minor (nova funcionalidade)
python build.py --type local --increment minor

# Build com incremento major (breaking changes)
python build.py --type local --increment major

# Build sem executar testes
python build.py --type local --no-tests
```

#### Build Docker
```bash
# Build Docker com incremento de vers√£o autom√°tico
python build.py --type docker

# Build para ambiente de produ√ß√£o
python build.py --type docker --env production --increment minor

# Build para desenvolvimento
python build.py --type docker --env development
```

#### Deploy Completo (Recomendado)
```bash
# Deploy completo: build + deploy + teste
python build.py --type deploy

# Deploy para produ√ß√£o com incremento minor
python build.py --type deploy --env production --increment minor

# Deploy para desenvolvimento
python build.py --type deploy --env development
```

### Gerenciar Vers√£o Manualmente

#### Visualizar Vers√£o
```bash
# Ver vers√£o atual com detalhes
python simple_version.py --show

# Ver apenas o n√∫mero da vers√£o
cat version.txt

# Ver vers√£o via API
curl http://localhost:5000/heartbeat
```

#### Incrementar Vers√£o
```bash
# Incremento patch: 1.1.0 -> 1.1.1 (corre√ß√µes)
python simple_version.py --increment patch

# Incremento minor: 1.1.0 -> 1.2.0 (novas funcionalidades)
python simple_version.py --increment minor

# Incremento major: 1.1.0 -> 2.0.0 (breaking changes)
python simple_version.py --increment major
```

#### Definir Vers√£o Espec√≠fica
```bash
# Definir vers√£o espec√≠fica
python simple_version.py --set 2.0.0

# Resetar para vers√£o inicial
python simple_version.py --set 1.0.0
```

### Verificar Vers√£o em Diferentes Ambientes

#### Local
```bash
# Via script Python
python simple_version.py --show

# Via arquivo
type version.txt  # Windows
cat version.txt   # Linux/Mac
```

#### Docker
```bash
# Via API (container rodando)
curl http://localhost:5000/heartbeat

# Via logs do container
docker-compose logs app | grep -i version

# Via labels da imagem
docker inspect flask-webscraping-api:latest
```

#### API Response
```json
{
  "version": "1.1.0",
  "version_info": {
    "version": "1.1.0",
    "build_date": "2025-01-26T10:30:00.123456",
    "environment": "production",
    "source": "docker"
  }
}
```

### Arquivos do Sistema de Versionamento
- **`version.txt`**: Arquivo principal com a vers√£o atual (ex: 1.1.0)
- **`simple_version.py`**: Script para gerenciar vers√µes manualmente
- **`build.py`**: Script unificado de build que incrementa automaticamente
- **`app.py`**: Aplica√ß√£o Flask que l√™ e exibe a vers√£o

### Fluxo de Trabalho Recomendado
1. **Desenvolvimento**: Use `python build.py --type local` para builds locais
2. **Teste**: Use `python build.py --type deploy` para testar em Docker
3. **Produ√ß√£o**: Use `python build.py --type deploy --env production --increment minor`
4. **Hotfix**: Use `python build.py --type deploy --increment patch`

### Vantagens do Sistema Simples
- ‚úÖ **Simplicidade**: Apenas um arquivo `version.txt`
- ‚úÖ **Independ√™ncia**: N√£o depende de Git ou ferramentas externas
- ‚úÖ **Automa√ß√£o**: Incremento autom√°tico nos builds
- ‚úÖ **Flexibilidade**: Controle manual quando necess√°rio
- ‚úÖ **Integra√ß√£o**: Funciona em local e Docker
- ‚úÖ **Visibilidade**: Vers√£o vis√≠vel na API e logs

## Desenvolvimento

### Desativar Ambiente Virtual
```bash
deactivate
```

### Atualizar Depend√™ncias
```bash
pip freeze > requirements.txt
```

## Logs e Debugging

A aplica√ß√£o roda em modo debug por padr√£o. Os logs incluem:
- Erros de requisi√ß√£o HTTP
- Problemas de parsing de tabelas
- Informa√ß√µes sobre tabelas n√£o encontradas

## Testes

### Executar Todos os Testes
```bash
python run_all_tests.py
```

### Testes Individuais
```bash
# Teste de heartbeat e endpoints b√°sicos
python test_heartbeat.py

# Teste de valida√ß√£o de par√¢metros
python test_validation.py

# Teste b√°sico da API
python test_api.py

# Teste detalhado da API
python detailed_test.py
```

### Tipos de Teste Dispon√≠veis
- **Heartbeat**: Verifica se a API est√° funcionando
- **Valida√ß√£o**: Testa as valida√ß√µes de par√¢metros `year` e `sub_option`
- **B√°sico**: Testa todos os endpoints principais
- **Detalhado**: An√°lise aprofundada da estrutura de resposta

## Notas Importantes

- A aplica√ß√£o faz scraping do site oficial da Embrapa
- Respeite os termos de uso do site fonte
- A estrutura das tabelas pode variar dependendo dos dados dispon√≠veis
- Alguns endpoints podem n√£o ter dados para determinados anos ou sub-op√ß√µes
- **Valida√ß√£o rigorosa**: Par√¢metros inv√°lidos retornam erro HTTP 400
- **Cache inteligente**: Dados s√£o armazenados em cache para melhor performance 